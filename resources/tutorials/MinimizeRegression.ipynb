{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuilding Regression\n",
    "\n",
    "This notebook shows how to learn regression parameters using SciPy's [optimization functions](https://docs.scipy.org/doc/scipy/reference/optimize.html).\n",
    "The purpose here is to learn the concept of *minimizing a loss function*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We're going to import our modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as sps\n",
    "import scipy.optimize as spopt\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(20201017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the Penguins data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN     NaN  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also going to create a utility function for plotting lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(intercept, slope, xmin, xmax, **kwargs):\n",
    "    xs = np.linspace(xmin, xmax, 100)\n",
    "    ys = intercept + slope * xs\n",
    "    plt.plot(xs, ys, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's standardize the variables, like we did in Week 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(xs):\n",
    "    xbar = xs.mean()\n",
    "    s = xs.std()\n",
    "    return (xs - xbar) / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create standardized versions of our variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>sex</th>\n",
       "      <th>mass</th>\n",
       "      <th>flipper</th>\n",
       "      <th>bill_len</th>\n",
       "      <th>bill_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.563317</td>\n",
       "      <td>-1.416272</td>\n",
       "      <td>-0.883205</td>\n",
       "      <td>0.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.500969</td>\n",
       "      <td>-1.060696</td>\n",
       "      <td>-0.809939</td>\n",
       "      <td>0.126003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.186793</td>\n",
       "      <td>-0.420660</td>\n",
       "      <td>-0.663408</td>\n",
       "      <td>0.429833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.937403</td>\n",
       "      <td>-0.562890</td>\n",
       "      <td>-1.322799</td>\n",
       "      <td>1.088129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.251578</td>\n",
       "      <td>0.432721</td>\n",
       "      <td>2.175637</td>\n",
       "      <td>1.341320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.999750</td>\n",
       "      <td>0.077145</td>\n",
       "      <td>-0.077282</td>\n",
       "      <td>0.480471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.532143</td>\n",
       "      <td>-0.562890</td>\n",
       "      <td>1.040019</td>\n",
       "      <td>0.531109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.126883</td>\n",
       "      <td>0.646066</td>\n",
       "      <td>1.259816</td>\n",
       "      <td>0.936215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.532143</td>\n",
       "      <td>-0.207315</td>\n",
       "      <td>1.149917</td>\n",
       "      <td>0.784300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species     sex      mass   flipper  bill_len  bill_depth\n",
       "0       Adelie    male -0.563317 -1.416272 -0.883205    0.784300\n",
       "1       Adelie  female -0.500969 -1.060696 -0.809939    0.126003\n",
       "2       Adelie  female -1.186793 -0.420660 -0.663408    0.429833\n",
       "3       Adelie     NaN       NaN       NaN       NaN         NaN\n",
       "4       Adelie  female -0.937403 -0.562890 -1.322799    1.088129\n",
       "..         ...     ...       ...       ...       ...         ...\n",
       "339  Chinstrap    male -0.251578  0.432721  2.175637    1.341320\n",
       "340  Chinstrap  female -0.999750  0.077145 -0.077282    0.480471\n",
       "341  Chinstrap    male -0.532143 -0.562890  1.040019    0.531109\n",
       "342  Chinstrap    male -0.126883  0.646066  1.259816    0.936215\n",
       "343  Chinstrap  female -0.532143 -0.207315  1.149917    0.784300\n",
       "\n",
       "[344 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguin_std = pd.DataFrame({\n",
    "    'species': penguins['species'],\n",
    "    'sex': penguins['sex'],\n",
    "    'mass': zscore(penguins['body_mass_g']),\n",
    "    'flipper': zscore(penguins['flipper_length_mm']),\n",
    "    'bill_len': zscore(penguins['bill_length_mm']),\n",
    "    'bill_depth': zscore(penguins['bill_depth_mm'])\n",
    "})\n",
    "penguin_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Regression\n",
    "\n",
    "OLS stands for *ordinary least squares*.  That is, it finds the solution that minimizes $\\mathrm{SS}_{\\mathrm{resid}}$, the sum of squared error (on the test data).\n",
    "\n",
    "Remember that the linear model looks like this:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1$$\n",
    "\n",
    "We can frame the problem of fitting a linear model as minimizing a *loss function*:\n",
    "\n",
    "$$\\begin{align*}\n",
    "L(\\beta_0, \\beta_1) & = \\sum_i (y_i - \\hat{y}_i)^2 \\\\\n",
    "\\beta_0, \\beta_1 & = \n",
    "\\underset{\\beta_0, \\beta_1}{\\operatorname{argmin}} L(\\beta_0, \\beta_1)\n",
    "\\end{align*}$$\n",
    "\n",
    "Before optimizing this, though, we need a function that will use coefficients to preidct the mass with flipper length.  This function will take its parameters as a list or array, for compatibility with APIs we'll see in a moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mass_uv(params, data=penguin_std):\n",
    "    b0, b1 = params\n",
    "    return b0 + data['flipper'] * b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict flipper length. Let's run a Statsmodels linear model to get the parameters so we can test this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>mass</td>       <th>  R-squared:         </th> <td>   0.759</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.758</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1071.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 17 Oct 2020</td> <th>  Prob (F-statistic):</th> <td>4.37e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:54:18</td>     <th>  Log-Likelihood:    </th> <td> -241.46</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   342</td>      <th>  AIC:               </th> <td>   486.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   340</td>      <th>  BIC:               </th> <td>   494.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 6.939e-17</td> <td>    0.027</td> <td> 2.61e-15</td> <td> 1.000</td> <td>   -0.052</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flipper</th>   <td>    0.8712</td> <td>    0.027</td> <td>   32.722</td> <td> 0.000</td> <td>    0.819</td> <td>    0.924</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.634</td> <th>  Durbin-Watson:     </th> <td>   2.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.060</td> <th>  Jarque-Bera (JB):  </th> <td>   5.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.313</td> <th>  Prob(JB):          </th> <td>  0.0613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.019</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   mass   R-squared:                       0.759\n",
       "Model:                            OLS   Adj. R-squared:                  0.758\n",
       "Method:                 Least Squares   F-statistic:                     1071.\n",
       "Date:                Sat, 17 Oct 2020   Prob (F-statistic):          4.37e-107\n",
       "Time:                        19:54:18   Log-Likelihood:                -241.46\n",
       "No. Observations:                 342   AIC:                             486.9\n",
       "Df Residuals:                     340   BIC:                             494.6\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   6.939e-17      0.027   2.61e-15      1.000      -0.052       0.052\n",
       "flipper        0.8712      0.027     32.722      0.000       0.819       0.924\n",
       "==============================================================================\n",
       "Omnibus:                        5.634   Durbin-Watson:                   2.190\n",
       "Prob(Omnibus):                  0.060   Jarque-Bera (JB):                5.585\n",
       "Skew:                           0.313   Prob(JB):                       0.0613\n",
       "Kurtosis:                       3.019   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv_mod = smf.ols('mass ~ flipper', data=penguin_std)\n",
    "uv_fit = uv_mod.fit()\n",
    "uv_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -1.233858\n",
       "1     -0.924080\n",
       "2     -0.366480\n",
       "3           NaN\n",
       "4     -0.490391\n",
       "         ...   \n",
       "339    0.376987\n",
       "340    0.067209\n",
       "341   -0.490391\n",
       "342    0.562854\n",
       "343   -0.180613\n",
       "Name: flipper, Length: 344, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = predict_mass_uv(uv_fit.params.values)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do these match the Statsmodels predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -1.233858\n",
       "1     -0.924080\n",
       "2     -0.366480\n",
       "4     -0.490391\n",
       "5     -0.676258\n",
       "         ...   \n",
       "339    0.376987\n",
       "340    0.067209\n",
       "341   -0.490391\n",
       "342    0.562854\n",
       "343   -0.180613\n",
       "Length: 342, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv_fit.fittedvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! Our linear model function is working correctly.\n",
    "\n",
    "Now let's make a *loss* function that computes the loss of a model with these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss_uv(params, data=penguin_std):\n",
    "    preds = predict_mass_uv(params, data)\n",
    "    err = data['mass'] - preds\n",
    "    return np.sum(np.square(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the squared error with our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.18355089922281"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_loss_uv(uv_fit.params.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should equal the residual sum of squares from Statsmodels, if we're writing this code correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.18355089922281"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv_fit.ssr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "Ok. We now have code that can correctly compute the sum of squares (loss), and the model predictions we're trying to optimize.\n",
    "\n",
    "Now we want to solve.  Let's do that.  The `scipy.optimize.minimize` function searches for a parameter vector (in this case, two coefficients) that minimizes a function (in this case, our loss function).\n",
    "\n",
    "It needs two things:\n",
    "\n",
    "1. The loss function\n",
    "2. An initial guess for the parameters\n",
    "\n",
    "We'll use standard normals for the parameter guess - since we have standardized variables, this will work pretty well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18652471,  0.9562162 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_guess = rng.standard_normal(2)\n",
    "init_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we minimize the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 82.18355089922284\n",
       " hess_inv: array([[0.17155552, 0.37538334],\n",
       "       [0.37538334, 0.82990841]])\n",
       "      jac: array([ 6.67572021e-06, -1.90734863e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 15\n",
       "      nit: 2\n",
       "     njev: 5\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([1.12829633e-09, 8.71201757e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = spopt.minimize(squared_loss_uv, init_guess)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `x` parameter has the optimized parameter values; `fun` has the smallest value of the function found. That's really close to our residual sum of squares from the OLS model!  The parameters are also pretty close too.  Let's put them side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS</th>\n",
       "      <th>SPOpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>6.938894e-17</td>\n",
       "      <td>1.128296e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flipper</th>\n",
       "      <td>8.712018e-01</td>\n",
       "      <td>8.712018e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    OLS         SPOpt\n",
       "Intercept  6.938894e-17  1.128296e-09\n",
       "flipper    8.712018e-01  8.712018e-01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'OLS': uv_fit.params,\n",
    "    'SPOpt': params.x\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient in particular is (nearly) identical, and the intercept is a little different but is essentially 0 in both cases.\n",
    "\n",
    "It's not going to be quite exact, because Statsmodels OLS uses an exact solution for the least squares problem, while what we get with `minimize` is an approximate solution.  Approximate solutions will be good for many other problems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Regression\n",
    "\n",
    "Now let's learn the multivariate model.  From the regression model, the one we settled on was:\n",
    "\n",
    "    mass ~ flipper + species * sex\n",
    "    \n",
    "This expands to:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_f + \\beta_2 x_c + \\beta_3 x_g + \\beta_4 x_m + \\beta_5 x_c x_m + \\beta_6 x_g x_m$$\n",
    "\n",
    "We're going to start by dummy-coding our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>sex</th>\n",
       "      <th>mass</th>\n",
       "      <th>flipper</th>\n",
       "      <th>bill_len</th>\n",
       "      <th>bill_depth</th>\n",
       "      <th>Chinstrap</th>\n",
       "      <th>Gentoo</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.563317</td>\n",
       "      <td>-1.416272</td>\n",
       "      <td>-0.883205</td>\n",
       "      <td>0.784300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.500969</td>\n",
       "      <td>-1.060696</td>\n",
       "      <td>-0.809939</td>\n",
       "      <td>0.126003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.186793</td>\n",
       "      <td>-0.420660</td>\n",
       "      <td>-0.663408</td>\n",
       "      <td>0.429833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.937403</td>\n",
       "      <td>-0.562890</td>\n",
       "      <td>-1.322799</td>\n",
       "      <td>1.088129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.251578</td>\n",
       "      <td>0.432721</td>\n",
       "      <td>2.175637</td>\n",
       "      <td>1.341320</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.999750</td>\n",
       "      <td>0.077145</td>\n",
       "      <td>-0.077282</td>\n",
       "      <td>0.480471</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.532143</td>\n",
       "      <td>-0.562890</td>\n",
       "      <td>1.040019</td>\n",
       "      <td>0.531109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.126883</td>\n",
       "      <td>0.646066</td>\n",
       "      <td>1.259816</td>\n",
       "      <td>0.936215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.532143</td>\n",
       "      <td>-0.207315</td>\n",
       "      <td>1.149917</td>\n",
       "      <td>0.784300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species     sex      mass   flipper  bill_len  bill_depth  Chinstrap  \\\n",
       "0       Adelie    male -0.563317 -1.416272 -0.883205    0.784300          0   \n",
       "1       Adelie  female -0.500969 -1.060696 -0.809939    0.126003          0   \n",
       "2       Adelie  female -1.186793 -0.420660 -0.663408    0.429833          0   \n",
       "3       Adelie     NaN       NaN       NaN       NaN         NaN          0   \n",
       "4       Adelie  female -0.937403 -0.562890 -1.322799    1.088129          0   \n",
       "..         ...     ...       ...       ...       ...         ...        ...   \n",
       "339  Chinstrap    male -0.251578  0.432721  2.175637    1.341320          1   \n",
       "340  Chinstrap  female -0.999750  0.077145 -0.077282    0.480471          1   \n",
       "341  Chinstrap    male -0.532143 -0.562890  1.040019    0.531109          1   \n",
       "342  Chinstrap    male -0.126883  0.646066  1.259816    0.936215          1   \n",
       "343  Chinstrap  female -0.532143 -0.207315  1.149917    0.784300          1   \n",
       "\n",
       "     Gentoo  male  \n",
       "0         0     1  \n",
       "1         0     0  \n",
       "2         0     0  \n",
       "3         0     0  \n",
       "4         0     0  \n",
       "..      ...   ...  \n",
       "339       0     1  \n",
       "340       0     0  \n",
       "341       0     1  \n",
       "342       0     1  \n",
       "343       0     0  \n",
       "\n",
       "[344 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguin_all = penguin_std.join(pd.get_dummies(penguin_std['species'], drop_first=True))\n",
    "penguin_all = penguin_all.join(pd.get_dummies(penguin_std['sex'], drop_first=True))\n",
    "penguin_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up our prediction function.  We're going to *vectorize* this - if we do a matrix multiply between a $n \\times k$ matrix and a $k$-dimensional array, we'll get an $n \\times 1$ array of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_mass_mv(params, data=penguin_all):\n",
    "    intercept = params[0]\n",
    "    slopes = params[1:]\n",
    "    cols = data[['flipper', 'Chinstrap', 'Gentoo', 'male']].copy()\n",
    "    cols['Chinstrap:male'] = cols['Chinstrap'] * cols['male']\n",
    "    cols['Gentoo:male'] = cols['Gentoo'] * cols['male']\n",
    "    return intercept + cols @ slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30068623, -0.46800143,  1.05910917, -1.55308712,  0.06762369,\n",
       "        0.47486707, -0.72624577])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_guess = rng.standard_normal(7)\n",
    "init_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our prediction function - should give us predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.031127\n",
       "1      0.797094\n",
       "2      0.497556\n",
       "3           NaN\n",
       "4      0.564120\n",
       "         ...   \n",
       "339    1.699772\n",
       "340    1.323691\n",
       "341    2.165720\n",
       "342    1.599926\n",
       "343    1.456819\n",
       "Length: 344, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mass_mv(init_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss_mv(params, data=penguin_all):\n",
    "    preds = pred_mass_mv(params, data)\n",
    "    err = data['mass'] - preds\n",
    "    return np.sum(np.square(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How bad is that loss with our guess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2150.413368100089"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_loss_mv(init_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's minimize the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 44.02326049720256\n",
       " hess_inv: array([[ 0.01480044,  0.00888065, -0.00903515, -0.02240841, -0.0094197 ,\n",
       "         0.00427484,  0.00407089],\n",
       "       [ 0.00888065,  0.00940691, -0.00278176, -0.0169299 , -0.00317235,\n",
       "        -0.00226389, -0.00251838],\n",
       "       [-0.00903515, -0.00278176,  0.0219765 ,  0.01141677,  0.00732328,\n",
       "        -0.02046506, -0.00564343],\n",
       "       [-0.02240841, -0.0169299 ,  0.01141677,  0.04498431,  0.01215354,\n",
       "        -0.00234171, -0.01004325],\n",
       "       [-0.0094197 , -0.00317235,  0.00732328,  0.01215354,  0.0143767 ,\n",
       "        -0.01249076, -0.01250795],\n",
       "       [ 0.00427484, -0.00226389, -0.02046506, -0.00234171, -0.01249076,\n",
       "         0.04323162,  0.01386635],\n",
       "       [ 0.00407089, -0.00251838, -0.00564343, -0.01004325, -0.01250795,\n",
       "         0.01386635,  0.03046714]])\n",
       "      jac: array([-0.00000000e+00,  0.00000000e+00,  4.76837158e-07,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 128\n",
       "      nit: 13\n",
       "     njev: 16\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-0.68863129,  0.35659433,  0.08029619,  0.97323106,  0.70694806,\n",
       "       -0.40084566,  0.0853413 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_opt = spopt.minimize(squared_loss_mv, init_guess)\n",
    "mv_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us an optimized residual sum of squares of 44!  If we compare with the regression notebook, the parameters are pretty close! They aren't quite in the same order, so we have to be careful, but this is clearly an approximation of the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
