
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="canonical" href="https://cs533.ekstrandom.net/F20/resources/glossary/">
      
      <link rel="icon" href="../../logo.png">
      <meta name="generator" content="mkdocs-1.2.1, mkdocs-material-7.1.8">
    
    
      
        <title>Glossary - Intro to Data Science</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.ca7ac06f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.f1a3b89f.min.css">
        
      
    
    
<link href="../../stylesheets/print.css" rel="stylesheet" media="print">

    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400,400i,700%7C&display=fallback">
        <style>:root{--md-text-font-family:"Lato";--md-code-font-family:""}</style>
      
    
    
    
      <link rel="stylesheet" href="../../stylesheets/custom.css">
    
    
      


    
    



  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Intro to Data Science" class="md-header__button md-logo" aria-label="Intro to Data Science" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path d="M208 352c-2.39 0-4.78.35-7.06 1.09C187.98 357.3 174.35 360 160 360c-14.35 0-27.98-2.7-40.95-6.91-2.28-.74-4.66-1.09-7.05-1.09C49.94 352-.33 402.48 0 464.62.14 490.88 21.73 512 48 512h224c26.27 0 47.86-21.12 48-47.38.33-62.14-49.94-112.62-112-112.62zm-48-32c53.02 0 96-42.98 96-96s-42.98-96-96-96-96 42.98-96 96 42.98 96 96 96zM592 0H208c-26.47 0-48 22.25-48 49.59V96c23.42 0 45.1 6.78 64 17.8V64h352v288h-64v-64H384v64h-76.24c19.1 16.69 33.12 38.73 39.69 64H592c26.47 0 48-22.25 48-49.59V49.59C640 22.25 618.47 0 592 0z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Intro to Data Science
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Glossary
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../.." class="md-tabs__link">
      Course Info
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../syllabus/" class="md-tabs__link">
      Syllabus
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../schedule/" class="md-tabs__link">
      Schedule
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../" class="md-tabs__link md-tabs__link--active">
        Resources
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../content/" class="md-tabs__link">
        Content
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../assignments/" class="md-tabs__link">
        Assignments
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Intro to Data Science" class="md-nav__button md-logo" aria-label="Intro to Data Science" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path d="M208 352c-2.39 0-4.78.35-7.06 1.09C187.98 357.3 174.35 360 160 360c-14.35 0-27.98-2.7-40.95-6.91-2.28-.74-4.66-1.09-7.05-1.09C49.94 352-.33 402.48 0 464.62.14 490.88 21.73 512 48 512h224c26.27 0 47.86-21.12 48-47.38.33-62.14-49.94-112.62-112-112.62zm-48-32c53.02 0 96-42.98 96-96s-42.98-96-96-96-96 42.98-96 96 42.98 96 96 96zM592 0H208c-26.47 0-48 22.25-48 49.59V96c23.42 0 45.1 6.78 64 17.8V64h352v288h-64v-64H384v64h-76.24c19.1 16.69 33.12 38.73 39.69 64H592c26.47 0 48-22.25 48-49.59V49.59C640 22.25 618.47 0 592 0z"/></svg>

    </a>
    Intro to Data Science
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Course Info
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../syllabus/" class="md-nav__link">
        Syllabus
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../schedule/" class="md-nav__link">
        Schedule
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        Resources
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Resources" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Resources
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Overview
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../software/" class="md-nav__link">
        Software Installation
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../onyx/" class="md-nav__link">
        Remotely Using Onyx
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Glossary
      </a>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../notebook-checklist/" class="md-nav__link">
        Notebook Checklist
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../problems/" class="md-nav__link">
        Common Problems
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../probability/" class="md-nav__link">
        Notes on Probability
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../git-resources/" class="md-nav__link">
        Git Resources
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/" class="md-nav__link">
        Tutorial Notebooks
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        Content
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Content" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Content
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/" class="md-nav__link">
        Course Content
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week1/" class="md-nav__link">
        Week 1 — Question
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week2/" class="md-nav__link">
        Week 2 — Description
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week3/" class="md-nav__link">
        Week 3 — Presentation
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week4/" class="md-nav__link">
        Week 4 — Inference
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week5/" class="md-nav__link">
        Week 5 — Filling In
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week6/" class="md-nav__link">
        Week 6 — Two Variables
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week7/" class="md-nav__link">
        Week 7 — Getting Data
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week8/" class="md-nav__link">
        Week 8 — Regression
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week9/" class="md-nav__link">
        Week 9 — Models & Prediction
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week10/" class="md-nav__link">
        Week 10 — Classification
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week11/" class="md-nav__link">
        Week 11 — Evaluation
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week12/" class="md-nav__link">
        Week 12 — Text
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week13/" class="md-nav__link">
        Week 13 — Unsupervised
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week14/" class="md-nav__link">
        Week 14 — Workflow
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../content/week15/" class="md-nav__link">
        Week 15 — What Next?
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      <label class="md-nav__link" for="__nav_6">
        Assignments
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Assignments" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Assignments
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/" class="md-nav__link">
        Index
      </a>
    </li>
  

          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2" type="checkbox" id="__nav_6_2" >
      
      <label class="md-nav__link" for="__nav_6_2">
        Assignment 0
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Assignment 0" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_2">
          <span class="md-nav__icon md-icon"></span>
          Assignment 0
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A0/" class="md-nav__link">
        Overview
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A0/A0-Notebook/" class="md-nav__link">
        CS 533 Assignment 0
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A0/A0-Solution.pdf" class="md-nav__link">
        PDF
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A1/" class="md-nav__link">
        Assignment 1
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A2/" class="md-nav__link">
        Assignment 2
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A3/" class="md-nav__link">
        Assignment 3
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A4/" class="md-nav__link">
        Assignment 4
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A5/" class="md-nav__link">
        Assignment 5
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A6/" class="md-nav__link">
        Assignment 6
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/A7/" class="md-nav__link">
        Assignment 7
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              



                
                
                <h1 id="glossary">Glossary</h1>
<p>We're going to learn many terms and concepts this semester.
This page catalogs many of the important ones, with pointers to the resources in which they are introduced.</p>
<div class="glossary">
<dl>
<dt>Ablation study</dt>
<dd>
<p>A study in which we turn off different components of a complex model to see how much each one contributes to the overall model's performance.</p>
<p>Introduced in <a href="../../content/week11/#ablation">Inference and Albation</a>.</p>
</dd>
<dt>Aggregate</dt>
<dd>
<p>A function that computes a single value from a series (or matrix) of values.
Often used to compute a <em>statistic</em>.</p>
<p>Introduced in <a href="../../content/week2/#group-agg"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Groups and Aggregates</a>.</p>
</dd>
<dt>Bayesianism</dt>
<dd>A school of thought for statistical inference and the interpretation of probability that is concerned with using probability to quantify <em>uncertainty</em> or <em>coherent states of belief</em>.
In statistical inference, this results in methods that quantify knowledge with probability distributions, and update those distributions based on the results of an experiment or data analysis.
Not to be confused with <em>Bayes' Theorem</em>, which is a fundamental building block of Bayesian inference but has many other uses as well.</dd>
<dt>Bayes' Theorem</dt>
<dd>
<p>A theorem or identity in probability theory that allows us to reverse a conditional probability:</p>
<div class="arithmatex">\[P(B|A) = \frac{P(A|B) P(B)}{P(A)}\]</div>
<p>Statisticians of all schools of thought make use of Bayes' theorem — all it does is relate <span class="arithmatex">\(P(A|B)\)</span> to <span class="arithmatex">\(P(B|A)\)</span>.</p>
<p>Introduced in <a href="../../content/week4/#joint-cond"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Joint and Conditional Probability</a>.</p>
</dd>
<dt>Bootstrap</dt>
<dd>
<p>A technique for estimating sampling distributions by repeatedly resampling the available sample with replacement.</p>
<p>Introduced in <a href="../../content/week4/#bootstrap"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> The Bootstrap</a>.</p>
</dd>
<dt>Central limit theorem</dt>
<dd>The theorem that describes the sampling distribution of the sample mean.
If we take a random sample <span class="arithmatex">\(X\)</span> from (most) populations with mean <span class="arithmatex">\(\mu\)</span> and variance <span class="arithmatex">\(\sigma^2\)</span>, the sample mean <span class="arithmatex">\(\bar{x} \sim \mathrm{Normal}(\mu, \sigma/\sqrt{n})\)</span>.</dd>
<dt>Classification</dt>
<dd>A problem where the goal is to predict a discrete class for an instance.
This is often <em>binary classification</em>, where instances are categorized into one of two classes.</dd>
<dt>Conditional Probability</dt>
<dd>
<p>The conditional probability <span class="arithmatex">\(P(B|A)\)</span> (read “the probability of <span class="arithmatex">\(B\)</span> given <span class="arithmatex">\(A\)</span>”) is the probability of <span class="arithmatex">\(B\)</span>, given that we know <span class="arithmatex">\(A\)</span> occured.
We can also discuss conditional expectation <span class="arithmatex">\(\mathrm{E}[X|A]\)</span>, the expected value of <span class="arithmatex">\(X\)</span> for those occurrances where <span class="arithmatex">\(A\)</span> occurred.</p>
<p>Introduced in <a href="../../content/week4/#joint-cond"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Joint and Conditional Probability</a>.</p>
</dd>
<dt>Confidence Interval</dt>
<dd>
<p>An interval used to estimate the precision of an estimate.
A 95% confidence interval is an interval computed from a procedure (including both taking a sample and computing a statistic from that sample) that, when repeated, will return an interval containing the true parameter value 95% of the time.
Discussed in <a href="../../content/week4/#confidence"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Confidence</a>, <a href="https://medium.com/@EpiEllie/having-confidence-in-confidence-intervals-8f881712d837">Having confidence in confidence intervals</a>, and <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda352.htm">Handbook section 1.3.5.2</a>.</p>
<p>A confidence interval is <strong>not</strong> a probabilistic statement about either the population mean <span class="arithmatex">\(\mu\)</span> or the sample mean <span class="arithmatex">\(\bar{x}\)</span>.</p>
</dd>
<dt>Correlation</dt>
<dd>
<p>The extent to which two variables change <em>with each other</em>.
If one variable usually increases when the other one increases, the variables are <em>correlated</em>; if one decreases when the other increases, they are <em>anticorrelated</em>.</p>
<p>Correlation is measured with the correlation coefficient:</p>
<div class="arithmatex">\[r = \frac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum(x_i - \bar{x})^2}\sqrt{\sum(y_i - \bar{y})^2}}\]</div>
<p>This is equivalent to the <strong>covariance</strong> scaled by the standard deviations of the variables:</p>
<div class="arithmatex">\[\mathrm{Cor}(X, Y) = \frac{\mathrm{Cov}(X, Y)}{\sigma_X \sigma_Y}\]</div>
</dd>
<dt>Degrees of Freedom</dt>
<dd>
<p>The number of observations in a series that can independently vary to affect a calculation.
This is usually the number of observations, minus the number of intermediate statistics.
For example, the degrees of freedom for the sample standard deviation for <span class="arithmatex">\(n\)</span> observations is <span class="arithmatex">\(n-1\)</span>, because one DoF is “used up” by the mean:</p>
<div class="arithmatex">\[s = \sqrt{\frac{\sum_i (x_i - \bar{x})^2}{n - 1}}\]</div>
</dd>
<dt>Elementary Event</dt>
<dd>
<p>In probability theory, an individual distinct outcome of a process we are modeling as random.</p>
<p>Introduced in <a href="../../content/week4/#probability"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Probability</a>.</p>
</dd>
<dt>Embedding</dt>
<dd>
<p>As a noun, a vector-space representation of a data point or instance.
This is often a lower-dimensional representation produced through some form of matrix decomposition such as SVD.</p>
<p>As a verb, to convert an instance to such a representation.</p>
</dd>
<dt id="envvar">Environment variable</dt>
<dd>
<p>A string variable associated with a process by the operating system.
Often used for configuring the behavior of software, such as the number of threads to use in parallel computation.
Child processes inherit their parents' environment variables.</p>
<p>Environment variables for the current process can be accessed and set in Python via the dictionary <code>os.environ</code>.</p>
<p>In the Unix shell, set an environment variable with:</p>
<pre><code>export MY_VAR="contents"
</code></pre>
<p>In PowerShell, set it with:</p>
<pre><code>$env:MY_VAR="contents"
</code></pre>
<p>Set an environment variable <em>before</em> running commands that need to be governed by it.</p>
</dd>
<dt>Euclidean norm</dt>
<dd>See <a href="#l2-norm">L₂ Norm</a></dd>
<dt>Event</dt>
<dd>
<p>In probability theory, an outcome that for which we want to estimate the probability.
Formally, given a set <span class="arithmatex">\(E\)</span> of elementary outcomes, an event is a set <span class="arithmatex">\(A \subseteq E\)</span>, and the set of possible events <span class="arithmatex">\(\mathcal{F}\)</span> forms a <em>sigma field</em>.</p>
<p>Introduced in <a href="../../content/week4/#probability"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Probability</a>.</p>
</dd>
<dt>Estimand</dt>
<dd>An unknown quantity that we try to estimate.  See <em>Estimator</em>.</dd>
<dt>Estimate</dt>
<dd><em>n.</em> A value computed to approximate the value of some estimand.  See <em>Estimator</em>.</dd>
<dd><em>v.</em> The process of computing an estimate for an estimand.</dd>
<dt>Estimator</dt>
<dd>
<p>A computation (or computed value) that we use to try to estimate an unknown value.
Formally, an <em>estimator</em> is a computation to produce an <em>estimate</em> of an <em>estimand</em>.
The sample mean <span class="arithmatex">\(\bar{x}\)</span>, as an abstract concept, is an estimator of the population mean, also as an abstract concept.
Any <em>particular</em> sample mean we compute, such as <span class="arithmatex">\(\bar{x} = 3.2\)</span>, is an <em>estimate</em> of the population mean <em>for that sample</em>.</p>
<p>Introduced in <a href="../../content/week4/#introduction"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Inference Introduction</a>.</p>
</dd>
<dt>Expected value</dt>
<dd>The mean of a random variable <span class="arithmatex">\(X\)</span>: <span class="arithmatex">\(\E[X] = \sum x P(x)\)</span> or <span class="arithmatex">\(\E[X] = \int x p(x) dx\)</span>.</dd>
<dt>Frequentism</dt>
<dd>A school of thought for statistical inference and the interpretation of probability that is concerned with probabilities as descriptions of the long-run behavior of a random process: how frequent would various outcomes be if the process were repeated infinitely many times?
In statistical inference, this results in methods that are characterized by their behavior if a sampling procedure or experiment were repeated, such as confidence intervals (defined in terms of the behavior of calculating them over multiple samples) and <em>p</em>-values (the probability that a random sample would produce a statistic at least as large as the observed statistic if the sampling procedure were repeated).</dd>
<dt>Hyperparameter</dt>
<dd>A value that controls a model's training or prediction behavior that is <strong>not</strong> learned from the data.
Examples include learning rates, iteration counts, and regularization terms.</dd>
<dt>Joint Probability</dt>
<dd>
<p>The joint probability <span class="arithmatex">\(P(A, B)\)</span> is the probability of both <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(B\)</span> occurring (in terms of underlying events, it's the probability that the elementary event <span class="arithmatex">\(\zeta\)</span> is in both <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(B\)</span>).
Equivalent to <span class="arithmatex">\(P(A \cap B)\)</span>.
Related to the conditional and marginal probabilities by <span class="arithmatex">\(P(A, B) = P(A|B) P(B)\)</span>.
Symmetric (<span class="arithmatex">\(P(A, B) = P(B, A)\)</span>).</p>
<p>Introduced in <a href="../../content/week4/#joint-cond"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Joint and Conditional Probability</a>.</p>
</dd>
<dt id="l1-norm">L₁ Norm</dt>
<dd>
<p>A measure of the magnitude of a vector, sometimes called the <em>Manhattan distance</em>.  It is the sum of the absolute values of the elements in the vector:</p>
<div class="arithmatex">\[\| \mathbf{x} \|_1 = \sum_i |x_i|\]</div>
</dd>
<dt id="l2-norm">L₂ Norm</dt>
<dd>
<p>A measure of the magnitude of a vector, also called the <em>Euclidean norm</em> or <em>Euclidean length</em>.  It is square root of the sum of squares of the elements in the vector:</p>
<div class="arithmatex">\[\| \mathbf{x} \|_2 = \sqrt{\sum_i x_i^2}\]</div>
</dd>
<dt>Leakage</dt>
<dd>When your predictive model benefits from information that would not be available when the model is in actual use.
Setting aside test data until the model is ready for final evaluation helps reduce leakage.</dd>
<dt>Linear model</dt>
<dd>
<p>A model of the form <span class="arithmatex">\(\hat{y} = \beta_0 + \sum_i \beta_i x_i\)</span>: it is the sum of scalar products.</p>
<p>Linear models are introduced in <a href="../../content/week8/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1V1M5 8v11h14V8H5m2 2h10v2H7v-2z"/></svg></span> Week 8</a>.</p>
</dd>
<dt id="logistic">Logistic function</dt>
<dd>
<p>A <em>sigmoid</em> function that maps unbounded real values to the range <span class="arithmatex">\((0,1)\)</span>:</p>
<div class="arithmatex">\[\mathrm{logistic}(x) = \frac{1}{1 + e^{-x}} = \frac{e^x}{e^x + 1}\]</div>
<p>The logistic function is the invert of the logit function.</p>
<p>Logistic regressions are introduced in <a href="../../content/week10/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1V1M5 8v11h14V8H5m2 2h10v2H7v-2z"/></svg></span> Week 10</a>.</p>
</dd>
<dt id="logit">Logit function</dt>
<dd>
<p>The inverse of the logistic function:</p>
<div class="arithmatex">\[\mathrm{logit(x)} = \mathrm{logistic}^{-1}(x) = \operatorname{log} \frac{x}{1-x} = \operatorname{log} x - \operatorname{log} (1-x)\]</div>
<p>Applying <em>logit</em> to a probability yields the <em>log odds</em>.</p>
</dd>
<dt>Majority-class classifier</dt>
<dd>A classifier that classifies every data point with the most common class from the training data.
If 72% of the training data is in class A, the majority-class classifier will classify every test point as A, no matter what its input feature values are.</dd>
<dt>Marginal Probability</dt>
<dd>
<p>The probability of a single event, or distribution of a single dimension, <span class="arithmatex">\(P(A)\)</span>.
Primarily used when we are talking about the probability of events (or expectation of variables) along one dimension of a <em>product space</em>, such as the suit or number of a card from a deck of playing cards.</p>
<p>Described in <a href="../../content/week4/#joint-cond"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Joint and Conditional Probability</a>.</p>
</dd>
<dt>Matrix</dt>
<dd>A two-dimensional array of numbers.
Alternatively, a linear map between vector spaces.</dd>
<dt>Matrix decomposition</dt>
<dd>
<p>A decomposition of a matrix into other matrices, such that multiplying the decomposition back together yields the original matrix or an approximation thereof.
An example is the <em>singular value decomposition</em> (SVD):</p>
<div class="arithmatex">\[M = P \Sigma Q^T\]</div>
<p>where <span class="arithmatex">\(P \in \Reals^{m \times k}\)</span> and <span class="arithmatex">\(Q \in \Reals^{n \times k}\)</span> are orthogonal, and <span class="arithmatex">\(\Sigma \in \Reals^{k \times k}\)</span> is diagonal.</p>
</dd>
<dt>Objective Function</dt>
<dd>
<p>A function describing a model's performance that is used as the goal for learning its parameters.
This can be a <strong>loss function</strong> (where the goal is to minimize it) or a <strong>utility function</strong> (which should be maximized).</p>
<p>Defined in <a href="../../content/week11/#intro"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Building and Evaluating Models</a>, and introduced in
<a href="../../content/week9/#optimizing-loss"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Optimizing Loss</a>.</p>
</dd>
<dt>Operationalization</dt>
<dd>
<p>The mapping of a goal or question to a specific, measurable quantity (or measurement procedure).
When we operationalize a question, we translate it into the precise computations and measurements we will use to attempt to answer it.</p>
<p>Introduced in <a href="../../content/week1/#asking"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Asking Questions</a>.</p>
</dd>
<dt id="odds">Odds</dt>
<dd>
<p>An alternative way of framing probability, as the ratio of the likelihood for or against an event:</p>
<div class="arithmatex">\[\Odds(A) = \frac{P(A)}{P(A^c)}\]</div>
<p>The <em>log odds</em> is a particularly convenient way of working with odds, and is <span class="arithmatex">\(\log P(A) - \log (1 - P(A))\)</span>.
See the <a href="../probability/#odds"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 10V4.5l5.5 5.5M5 3c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V9l-6-6H5z"/></svg></span> probability notes</a>.</p>
</dd>
<dt id="odds-ratio">Odds ratio</dt>
<dd>
<p>The ratio of the odds of two different outcomes.</p>
<div class="arithmatex">\[\operatorname{OR}(A, B) = \frac{\Odds(A)}{\Odds{B}}\]</div>
<p>See the <a href="../probability/#odds"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 10V4.5l5.5 5.5M5 3c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V9l-6-6H5z"/></svg></span> probability notes</a>.</p>
</dd>
<dt overfitting="overfitting">Overfitting</dt>
<dd>
<p>When a model learns too much from its training data, so it cannot do an effective job of predicting future unseen data.</p>
<p>Introduced in <a href="../../content/week9/#overfitting"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Overfitting</a>.</p>
</dd>
<dt>Parameter</dt>
<dd>
<p>In <em>inferential statistics</em>: a “true” value in the population, such as the mean flipper length of Chinstrap penguins.
The goal of inferential statistics is often to estimate parameters, because we typically do not have direct access to them.</p>
<p>Introduced in <a href="../../content/week4/#sampling"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Sampling</a>.</p>
</dd>
<dd>
<p>In <em>model fitting</em>: a variable in a statistical or machine learning model whose value is learned from the data.
Contrast <em>hyper-parameter</em>, a variable that controls the model or the model-fitting process but is not learned from the data.</p>
</dd>
<dt>Population</dt>
<dd>
<p>The complete set of entities we want to study.  This is not only all entities that <em>do</em> exist, but under some philosophies, all entities that <em>could</em> exist.
For example, the set of all possible adult Chinstrap penguins would be the population.</p>
<p>Discussed in more detail in <a href="../../content/week4/#sampling"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Sampling</a>.</p>
</dd>
<dt>P-value</dt>
<dd>
<p>In hypothesis testing, the probability that the null hypothesis (<span class="arithmatex">\(H_0\)</span>) would produce a value as large as the observed value.
Typically the null hypothesis is an appropriate formalization of “nothing interesting”, so the <em>p</em>-value is the probability of seeing an effect as large as the one observed if there is no true effect to observe.</p>
<p>Discussed in <a href="../../content/week4/#hypotest"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Testing Hypotheses</a></p>
</dd>
<dt>Regression</dt>
<dd>
<p>A modeling or prediction problem where we try to estimate or predict a continuous variable <span class="arithmatex">\(Y\)</span>.</p>
<p>This is the focus of <a href="../../content/week8/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1V1M5 8v11h14V8H5m2 2h10v2H7v-2z"/></svg></span> Week 8</a>.</p>
</dd>
<dt>Regularization</dt>
<dd>
<p>A penalty term added to a loss function, typically penalizing large values.  Used to encourage sparsity or to require coefficients to be supported by larger quantiies of data.</p>
<p>Introduced in <a href="../../pages/content/week11/index.md#regularization">:a-video Regularization</a>.</p>
</dd>
<dt>Residual</dt>
<dd>
<p>The error in estimating a variable with a model.  For a model fitting an estimator <span class="arithmatex">\(\hat{Y}\)</span> for a variable <span class="arithmatex">\(Y\)</span>, the residuals are <span class="arithmatex">\(\epsilon_i = y - \hat{y}\)</span>.
This is reflected in the full linear model: <span class="arithmatex">\(y_i = \beta_0 + \sum_j \beta_j x_{ij} + \epsilon_i\)</span>.</p>
<p>Introduced in <a href="../../content/week8/#single-regression"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Single Regression</a>.</p>
</dd>
<dt>Sample</dt>
<dd>
<p><em>n.</em> A subset of the population, for which we have observations.</p>
<p>Discussed in more detail in <a href="../../content/week4/#sampling"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Sampling</a>.</p>
</dd>
<dt>Sample Size</dt>
<dd>The number of items in the sample.  Often denoted <span class="arithmatex">\(n\)</span>.</dd>
<dt>Sampling distribution</dt>
<dd>The distribution of a statistic when it is computed over many repeated samples of the same size from the same population.
The sampling distribution of the sample mean from a population with mean <span class="arithmatex">\(\mu\)</span> and variance <span class="arithmatex">\(\sigma^2\)</span> is <span class="arithmatex">\(\mathrm{Normal}(\mu, \sigma/\sqrt{n})\)</span>.</dd>
<dt>Statistic</dt>
<dd>
<p>A value computed from a set of observations.
For example, the sample mean <span class="arithmatex">\(\bar{x} = n^{-1} \sum_i x_i\)</span> is a statistic of a sample <span class="arithmatex">\(X = \langle x_i, \dots, x_n \rangle\)</span>.</p>
<p>Discussed in <a href="../../content/week4/#introduction"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Inference Intro</a>.</p>
</dd>
<dt>Standard deviation</dt>
<dd>
<p>A measure of the spread of a random variable.  It is the square root of the mean squared deviation from the mean:</p>
<div class="arithmatex">\[\sigma_X = \sqrt{\frac{\sum_i (x_i - \bar{x})^2}{n}}\]</div>
<p>When computing the standard deviation from a sample, we instead compute the <strong>sample standard deviation</strong>:</p>
<div class="arithmatex">\[s = \sqrt{\frac{\sum_i (x_i - \bar{x})^2}{n - 1}}\]</div>
</dd>
<dt>Standard error</dt>
<dd>
<p>The standard deviation of the <em>sampling distribution</em> of a statistic.  The standard error of the mean (Pandas function <code>.sem</code>) is <span class="arithmatex">\(s/\sqrt{n}\)</span>.</p>
<p>Discussed in <a href="../../content/week4/#confidence"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Confidence</a>.</p>
</dd>
<dt><em>t</em>-test</dt>
<dd>
<p>A statistical test for means of normally-distributed data.  T-tests come in three varieties:</p>
<ol>
<li>One-sample <em>t</em>-test that tests whether a single mean is different from zero (or another fixed value <span class="arithmatex">\(\mu_0\)</span>).  <span class="arithmatex">\(H_0: \mu=0\)</span></li>
<li>Two-sample independent <em>t</em>-test that tests whether the means of two independent samples are the same.  <span class="arithmatex">\(H_0: \mu_1 = \mu_2\)</span></li>
<li>Paired <em>t</em>-test that tests, for a sample of paired observations, whether the mean difference between observations for each sample is zero (the measurements are, on average, the same).  <span class="arithmatex">\(H_0: \mu_{x_{i1} - x_{i2}} = 0\)</span></li>
</ol>
<p>Discussed in <a href="../../content/week4/#hypotest"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> Testing Hypotheses</a>, <a href="../../content/week5/#ttest"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4z"/></svg></span> T-tests</a>, and associated readings.</p>
</dd>
<dt>Variance</dt>
<dd>
<p>A measure of the spread of a random variable (which may be observable quantities in the population).</p>
<div class="arithmatex">\[\Var(X) = \E[(X - \E[X])^2]\]</div>
<p>Variance is the square of the standard deviation, and is sometimes written <span class="arithmatex">\(\sigma^2\)</span>.</p>
</dd>
<dt>Vector</dt>
<dd>A sequence or array of numbers; <span class="arithmatex">\(\mathbf{x} = [x_1, x_2, \dots, x_n]\)</span> is an <span class="arithmatex">\(n\)</span>-dimensional vector.</dd>
<dt>Vectorization</dt>
<dd>Writing a computation so that mathematical operations are done across entire arrays at a time, rather than looping over individual data points in Python code.</dd>
<dt>Unbiased estimator</dt>
<dd>An estimator whose expected value is the population parameter.</dd>
</dl>
</div>
                
              

              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../onyx/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Remotely Using Onyx" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Remotely Using Onyx
            </div>
          </div>
        </a>
      
      
        
        <a href="../notebook-checklist/" class="md-footer__link md-footer__link--next" aria-label="Next: Notebook Checklist" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Notebook Checklist
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright ⓒ 2020 Michael D. Ekstrand. All rights reserved.
No part of this site may be copied or redistributed without the
written consent of the author.

          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
<script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.b0710199.min.js", "version": {"provider": "mike"}}</script>
    
<!-- <script src="../../js/katex.mjs" type="module" async></script> -->
<script src="../../js/frobnicate.js" async></script>
<script data-goatcounter="https://cs533.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>

    
      <script src="../../assets/javascripts/bundle.76f349be.min.js"></script>
      
        <script src="../../js/math-config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>