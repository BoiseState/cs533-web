{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f156c64",
   "metadata": {},
   "source": [
    "# SciKit-Learn Linear Regression Demo\n",
    "\n",
    "This notebook demonstrates running a linear regression with {py:class}`sklearn.linear_model.LinearRegression`, and comparing its results with those of a model from {py:func}`statsmodels.formula.api.ols`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610ea6e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import our basic modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08a5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a8d41",
   "metadata": {},
   "source": [
    "And initialize the RNG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e29b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeedSequence(\n",
       "    entropy=20211026,\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seedbank\n",
    "seedbank.initialize(20211026)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febb12f",
   "metadata": {},
   "source": [
    "And we'll load the movies we've been working with in several other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9f33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/hetrec2011-ml/movies.dat', sep='\\t', encoding='latin1',\n",
    "                     na_values='\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f16dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10197 entries, 0 to 10196\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      10197 non-null  int64  \n",
      " 1   title                   10197 non-null  object \n",
      " 2   imdbID                  10197 non-null  int64  \n",
      " 3   spanishTitle            10197 non-null  object \n",
      " 4   imdbPictureURL          10016 non-null  object \n",
      " 5   year                    10197 non-null  int64  \n",
      " 6   rtID                    9886 non-null   object \n",
      " 7   rtAllCriticsRating      9967 non-null   float64\n",
      " 8   rtAllCriticsNumReviews  9967 non-null   float64\n",
      " 9   rtAllCriticsNumFresh    9967 non-null   float64\n",
      " 10  rtAllCriticsNumRotten   9967 non-null   float64\n",
      " 11  rtAllCriticsScore       9967 non-null   float64\n",
      " 12  rtTopCriticsRating      9967 non-null   float64\n",
      " 13  rtTopCriticsNumReviews  9967 non-null   float64\n",
      " 14  rtTopCriticsNumFresh    9967 non-null   float64\n",
      " 15  rtTopCriticsNumRotten   9967 non-null   float64\n",
      " 16  rtTopCriticsScore       9967 non-null   float64\n",
      " 17  rtAudienceRating        9967 non-null   float64\n",
      " 18  rtAudienceNumRatings    9967 non-null   float64\n",
      " 19  rtAudienceScore         9967 non-null   float64\n",
      " 20  rtPictureURL            9967 non-null   object \n",
      "dtypes: float64(13), int64(3), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201a218b",
   "metadata": {},
   "source": [
    "And clear out the zeros, as discussed in [Missing Data](MissingData.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec090fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[movies['rtAllCriticsRating'] == 0, 'rtAllCriticsRating'] = np.nan\n",
    "movies.loc[movies['rtAudienceRating'] == 0, 'rtAudienceRating'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a9e3a",
   "metadata": {},
   "source": [
    "Finally, we'll create a test set of movies, and store the rest in training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c343e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies = movies.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0eb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = pd.Series(True, index=movies.index)\n",
    "train_mask[test_movies.index] = False\n",
    "train_movies = movies[train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5dbe4",
   "metadata": {},
   "source": [
    "We could also do this with {py:func}`sklearn.model_selection.train_test_split`, but I'm using Pandas directly here so we can see clearly what the split is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7632c41",
   "metadata": {},
   "source": [
    "## Statsmodels\n",
    "\n",
    "We're first going to use Statsmodels to compute a linear regression, like we have done on other data sets.  Our goal is to use the all-critics rating to predict the audience rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308619f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>rtAudienceRating</td> <th>  R-squared:         </th> <td>   0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6002.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 Oct 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:30:25</td>     <th>  Log-Likelihood:    </th> <td> -1554.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5749</td>      <th>  AIC:               </th> <td>   3113.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5747</td>      <th>  BIC:               </th> <td>   3127.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>    2.0949</td> <td>    0.017</td> <td>  121.401</td> <td> 0.000</td> <td>    2.061</td> <td>    2.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rtAllCriticsRating</th> <td>    0.2137</td> <td>    0.003</td> <td>   77.474</td> <td> 0.000</td> <td>    0.208</td> <td>    0.219</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.811</td> <th>  Durbin-Watson:     </th> <td>   1.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  31.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.064</td> <th>  Prob(JB):          </th> <td>1.40e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.340</td> <th>  Cond. No.          </th> <td>    26.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       rtAudienceRating   R-squared:                       0.511\n",
       "Model:                            OLS   Adj. R-squared:                  0.511\n",
       "Method:                 Least Squares   F-statistic:                     6002.\n",
       "Date:                Thu, 28 Oct 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:30:25   Log-Likelihood:                -1554.7\n",
       "No. Observations:                5749   AIC:                             3113.\n",
       "Df Residuals:                    5747   BIC:                             3127.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept              2.0949      0.017    121.401      0.000       2.061       2.129\n",
       "rtAllCriticsRating     0.2137      0.003     77.474      0.000       0.208       0.219\n",
       "==============================================================================\n",
       "Omnibus:                       24.811   Durbin-Watson:                   1.863\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.568\n",
       "Skew:                           0.064   Prob(JB):                     1.40e-07\n",
       "Kurtosis:                       3.340   Cond. No.                         26.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_sm = smf.ols('rtAudienceRating ~ rtAllCriticsRating', data=train_movies)\n",
    "lm_sm_fit = lm_sm.fit()\n",
    "lm_sm_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce8c9b0",
   "metadata": {},
   "source": [
    "We could also try to do this with a standardized predictor variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77951151",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_ratings = train_movies['rtAllCriticsRating']\n",
    "cr_mean = critic_ratings.mean()\n",
    "cr_std = critic_ratings.std()\n",
    "critic_std = (critic_ratings - cr_mean) / cr_std\n",
    "train_norm = pd.DataFrame({\n",
    "    'critics': critic_std,\n",
    "    'audience': train_movies['rtAudienceRating']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcacfb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>audience</td>     <th>  R-squared:         </th> <td>   0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6002.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 Oct 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:30:25</td>     <th>  Log-Likelihood:    </th> <td> -1554.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5749</td>      <th>  AIC:               </th> <td>   3113.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5747</td>      <th>  BIC:               </th> <td>   3127.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    3.3926</td> <td>    0.004</td> <td>  811.043</td> <td> 0.000</td> <td>    3.384</td> <td>    3.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>critics</th>   <td>    0.3271</td> <td>    0.004</td> <td>   77.474</td> <td> 0.000</td> <td>    0.319</td> <td>    0.335</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.811</td> <th>  Durbin-Watson:     </th> <td>   1.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  31.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.064</td> <th>  Prob(JB):          </th> <td>1.40e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.340</td> <th>  Cond. No.          </th> <td>    1.01</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               audience   R-squared:                       0.511\n",
       "Model:                            OLS   Adj. R-squared:                  0.511\n",
       "Method:                 Least Squares   F-statistic:                     6002.\n",
       "Date:                Thu, 28 Oct 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:30:25   Log-Likelihood:                -1554.7\n",
       "No. Observations:                5749   AIC:                             3113.\n",
       "Df Residuals:                    5747   BIC:                             3127.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.3926      0.004    811.043      0.000       3.384       3.401\n",
       "critics        0.3271      0.004     77.474      0.000       0.319       0.335\n",
       "==============================================================================\n",
       "Omnibus:                       24.811   Durbin-Watson:                   1.863\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.568\n",
       "Skew:                           0.064   Prob(JB):                     1.40e-07\n",
       "Kurtosis:                       3.340   Cond. No.                         1.01\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_nsm = smf.ols('audience ~ critics', data=train_norm)\n",
    "lm_nsm_fit = lm_nsm.fit()\n",
    "lm_nsm_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb2882",
   "metadata": {},
   "source": [
    "This means that an increase of 1 standard deviation in the mean critic rating corresponds to an increase of 1 in the audience rating (since the audience ratings have *not* been standardized, it is 1 actual mean rating value, not 1 standard deviation in the response variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0abeefa",
   "metadata": {},
   "source": [
    "## SciKit-Learn\n",
    "\n",
    "Now we want to implement this model with SciKit-Learn's linear regression model.\n",
    "\n",
    "Import the linear regression class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f099c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa859403",
   "metadata": {},
   "source": [
    "SciKit-Learn doesn't automatically drop missing data, so we're going to create a filtered copy of our training data that doesn't have nulls in our predictor or outcome variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d89d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filt = train_movies.dropna(subset=['rtAllCriticsRating', 'rtAudienceRating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee3b11",
   "metadata": {},
   "source": [
    "Now we're going to create an `X` matrix with one column to contain our predictor variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701ed4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rtAllCriticsRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rtAllCriticsRating\n",
       "0                 9.0\n",
       "1                 5.6\n",
       "4                 5.3\n",
       "5                 7.7\n",
       "6                 7.4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_filt[['rtAllCriticsRating']]\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9c56b",
   "metadata": {},
   "source": [
    "And a `y` vector with the outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ffc47e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.7\n",
       "1    3.2\n",
       "4    3.0\n",
       "5    3.9\n",
       "6    3.8\n",
       "Name: rtAudienceRating, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_filt['rtAudienceRating']\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c071b6",
   "metadata": {},
   "source": [
    "With the data prepared, we can create and train our linear regression object. {py:class}`sklearn.linear_model.LinearRegression` does not support regularization, so we can just use it as-is to get a model equivalent to Statsmodels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3366afc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9945eef",
   "metadata": {},
   "source": [
    "Let's look at its coefficient(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6b3dc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21366369])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fb809",
   "metadata": {},
   "source": [
    "That's exactly what we got from statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c690042c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0949060615377193"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766255e",
   "metadata": {},
   "source": [
    "Also the same.\n",
    "\n",
    "Let's create a test `X` matrix to measure some predictions, after filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebcd3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies = test_movies.dropna(subset=['rtAllCriticsRating', 'rtAudienceRating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bc122b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_movies[['rtAllCriticsRating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba67b2b",
   "metadata": {},
   "source": [
    "And a `y` that contains the outcomes for the same movies (make sure you understand how this next row works):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c9b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_movies.loc[test_X.index, 'rtAudienceRating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed0774",
   "metadata": {},
   "source": [
    "And we can generate predictions — SciKit-Learn doesn't know about Pandas, so it will be an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f5ed6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.95378017, 3.56918553, 3.01365993, ..., 2.88546172, 3.33415547,\n",
       "       3.44098731])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linreg.predict(test_X)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc98bf",
   "metadata": {},
   "source": [
    "And we can compute our errors and our mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7530870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8979    0.146220\n",
       "6752   -0.069186\n",
       "904    -0.213660\n",
       "2293    0.453052\n",
       "4588   -0.221363\n",
       "          ...   \n",
       "625    -0.476017\n",
       "5342   -0.476017\n",
       "8581    0.314538\n",
       "6114   -0.234155\n",
       "702    -0.540987\n",
       "Name: rtAudienceRating, Length: 1463, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = test_y - preds\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edcf51a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09531922808833015"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554081a8",
   "metadata": {},
   "source": [
    "The {py:func}`sklearn.metrics.mean_squared_error` function can do mean squared error for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a6d2d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09531922808833015"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60649290",
   "metadata": {},
   "source": [
    "## Standardizing with SciKit-Learn\n",
    "\n",
    "Now let's think about that standardized model.  We can do it with {py:class}`sklearn.preprocessing.StandardScaler` and a pipeline.  Import our classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cd82109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90ac684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('predict', LinearRegression())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('predict', LinearRegression())\n",
    "])\n",
    "lm_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35631c",
   "metadata": {},
   "source": [
    "We can fit the whole model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4785fc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('predict', LinearRegression())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_pipe.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32dfd5",
   "metadata": {},
   "source": [
    "Now let's see the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6de7e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32407576])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_pipe.named_steps['predict'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721b5cd",
   "metadata": {},
   "source": [
    "That matches what we got from statsmodels for this model!  Let's check our prediction error - it should be the same, since the new coefficient and intercept will compensate for the scaling to produce the same predictions (if we had regularization, this would not be true):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bde6b575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09531922808833014"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_y, lm_pipe.predict(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b2c56f",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Finally, I would like to demonstrate {py:class}`sklearn.linear_model.Ridge` to try this with L2 regression; in particular, we'll use {py:class}`sklearn.linear_model.RidgeCV` to learn a good regression strength with cross-validation on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc8540ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28bae419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('predict',\n",
       "                 RidgeCV(alphas=array([1.e-03, 1.e-01, 1.e+00, 5.e+00, 1.e+01, 2.e+01])))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('predict', RidgeCV([0.001, 0.1, 1, 5, 10, 20]))\n",
    "])\n",
    "reg_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150602d",
   "metadata": {},
   "source": [
    "Fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d525ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('predict',\n",
       "                 RidgeCV(alphas=array([1.e-03, 1.e-01, 1.e+00, 5.e+00, 1.e+01, 2.e+01])))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pipe.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea2e26",
   "metadata": {},
   "source": [
    "What regularization did it learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed062507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pipe.named_steps['predict'].alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd3dc6",
   "metadata": {},
   "source": [
    "And let's look at the prediction accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e115fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0953203458413433"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_y, reg_pipe.predict(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd71df6",
   "metadata": {},
   "source": [
    "Very, very slightly higher. Even with a very simple model, regularization can sometimes improve generalization. The difference in this case is almost certainly not statistically significant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
