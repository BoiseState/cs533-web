{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector Example\n",
    "\n",
    "This notebook demonstrates a spam detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some more helper libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And SciKit algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up our RNG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(20201106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TREC Spam\n",
    "\n",
    "Now we're going to load the TREC Spam data set.\n",
    "\n",
    "I downloaded this data from <https://plg.uwaterloo.ca/~gvcormac/treccorpus07/>, and converted the TGZ file from TREC to a Zip file so that we can read it directly from the compressed file.  This is because each e-mail is in a separate file, all in the same directory; a directory with 75K files does not perform well on sime file systems.  Here is the command I used to convert it (with Node.js installed):\n",
    "\n",
    "    npx tar-to-zip trec07p.tgz\n",
    "\n",
    "We're going to start by opening the zip file so we can access its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_zf = ZipFile('trec07p.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to load the labels â€” these are in the file `trec07p/full/index`.  We'll get a data frame, which contains the class (spam or ham) and the filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/inmail.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/inmail.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/inmail.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/inmail.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/inmail.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label              path\n",
       "0  spam  ../data/inmail.1\n",
       "1   ham  ../data/inmail.2\n",
       "2  spam  ../data/inmail.3\n",
       "3  spam  ../data/inmail.4\n",
       "4  spam  ../data/inmail.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with trec_zf.open('trec07p/full/index') as idxf:\n",
    "    trec_labels = pd.read_table(idxf, sep=' ', names=['label', 'path'])\n",
    "trec_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75419 entries, 0 to 75418\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   75419 non-null  object\n",
      " 1   path    75419 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.9 MB\n"
     ]
    }
   ],
   "source": [
    "trec_labels.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double-check that we don't have any duplicate paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75419"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trec_labels['path'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these filenames to extract the individual messages.  Let's do this:\n",
    "\n",
    "1. Extract the filename (after the `/`) for use as a key\n",
    "2. Load each file's contents into a string\n",
    "3. Merge with labels for a labeled spam/ham data set\n",
    "\n",
    "Start by replacing everything up to the final `/` with nothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/inmail.1</td>\n",
       "      <td>inmail.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/inmail.2</td>\n",
       "      <td>inmail.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/inmail.3</td>\n",
       "      <td>inmail.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/inmail.4</td>\n",
       "      <td>inmail.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>../data/inmail.5</td>\n",
       "      <td>inmail.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label              path      name\n",
       "0  spam  ../data/inmail.1  inmail.1\n",
       "1   ham  ../data/inmail.2  inmail.2\n",
       "2  spam  ../data/inmail.3  inmail.3\n",
       "3  spam  ../data/inmail.4  inmail.4\n",
       "4  spam  ../data/inmail.5  inmail.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trec_labels['name'] = trec_labels['path'].str.replace(r'^.*/', '')\n",
    "trec_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to load all the mails. No way to get around doing this as a loop - we could do it with `apply`, but that's just a loop.  We'll put it in a dictionary, then convert that to a series; the result is a series indexed by name, whose values are the e-mails.  We're also going to use TQDM to get a progress bar.\n",
    "\n",
    "While we are loading the data, we will also perform our **decoding** and **text normalization** steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb300b9b64ad440ab818cb6f97b9f80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=75419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75419"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trec_mails = {}\n",
    "for name in tqdm(trec_labels['name']):\n",
    "    path = f'trec07p/data/{name}'\n",
    "    with trec_zf.open(path) as mailf:\n",
    "        content = mailf.read()\n",
    "        content = content.decode('latin1')\n",
    "        content = unicodedata.normalize('NFKD', content)\n",
    "        trec_mails[name] = content\n",
    "trec_mails = pd.Series(trec_mails, name='content')\n",
    "len(trec_mails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can merge with the labels.  Let's create an `IsSpam` logical to mark the spams, then merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>IsSpam</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inmail.1</th>\n",
       "      <td>spam</td>\n",
       "      <td>True</td>\n",
       "      <td>From RickyAmes@aol.com  Sun Apr  8 13:07:32 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmail.2</th>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "      <td>From bounce-debian-mirrors=ktwarwic=speedy.uwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmail.3</th>\n",
       "      <td>spam</td>\n",
       "      <td>True</td>\n",
       "      <td>From 7stocknews@tractionmarketing.com  Sun Apr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmail.4</th>\n",
       "      <td>spam</td>\n",
       "      <td>True</td>\n",
       "      <td>From vqucsmdfgvsg@ruraltek.com  Sun Apr  8 13:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmail.5</th>\n",
       "      <td>spam</td>\n",
       "      <td>True</td>\n",
       "      <td>From dcube@totalink.net  Sun Apr  8 13:19:30 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  IsSpam                                            content\n",
       "name                                                                     \n",
       "inmail.1  spam    True  From RickyAmes@aol.com  Sun Apr  8 13:07:32 20...\n",
       "inmail.2   ham   False  From bounce-debian-mirrors=ktwarwic=speedy.uwa...\n",
       "inmail.3  spam    True  From 7stocknews@tractionmarketing.com  Sun Apr...\n",
       "inmail.4  spam    True  From vqucsmdfgvsg@ruraltek.com  Sun Apr  8 13:...\n",
       "inmail.5  spam    True  From dcube@totalink.net  Sun Apr  8 13:19:30 2..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trec_labels['IsSpam'] = trec_labels['label'] == 'spam'\n",
    "trec_data = trec_labels.set_index('name')[['label', 'IsSpam']].join(trec_mails)\n",
    "trec_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 75419 entries, inmail.1 to inmail.75419\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    75419 non-null  object\n",
      " 1   IsSpam   75419 non-null  bool  \n",
      " 2   content  75419 non-null  object\n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 622.1 MB\n"
     ]
    }
   ],
   "source": [
    "trec_data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_test = trec_data.sample(frac=0.2, random_state=rng)\n",
    "mask = pd.Series(True, index=trec_data.index)\n",
    "mask[trec_test.index] = False\n",
    "trec_train = trec_data[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "How are spam and ham distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21c12f64dc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(trec_train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more spams than hams.  What is the fraction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.665318637606696"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(trec_train['IsSpam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a majority-class classifier and a randomized classifier (that will return 'Spam' with the probability learned from the data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj_class = DummyClassifier(strategy='most_frequent')\n",
    "rnd_class = DummyClassifier(strategy='stratified', random_state=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train them and view classification reports on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michaelekstrand\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.00      0.00      0.00     20193\n",
      "        spam       0.67      1.00      0.80     40142\n",
      "\n",
      "    accuracy                           0.67     60335\n",
      "   macro avg       0.33      0.50      0.40     60335\n",
      "weighted avg       0.44      0.67      0.53     60335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maj_class.fit(trec_train['content'], trec_train['label'])\n",
    "print(classification_report(trec_train['label'], maj_class.predict(trec_train['content'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.34      0.34      0.34     20193\n",
      "        spam       0.67      0.66      0.67     40142\n",
      "\n",
      "    accuracy                           0.55     60335\n",
      "   macro avg       0.50      0.50      0.50     60335\n",
      "weighted avg       0.56      0.55      0.55     60335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd_class.fit(trec_train['content'], trec_train['label'])\n",
    "print(classification_report(trec_train['label'], rnd_class.predict(trec_train['content'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Now let's build a real spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorize', CountVectorizer(encoding='latin1')),\n",
       "                ('classify', MultinomialNB())])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_class = Pipeline([\n",
    "    ('vectorize', CountVectorizer()),\n",
    "    ('classify', MultinomialNB())\n",
    "])\n",
    "nb_class.fit(trec_train['content'], trec_train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it do on the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00     20193\n",
      "        spam       1.00      1.00      1.00     40142\n",
      "\n",
      "    accuracy                           1.00     60335\n",
      "   macro avg       1.00      1.00      1.00     60335\n",
      "weighted avg       1.00      1.00      1.00     60335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(trec_train['label'], nb_class.predict(trec_train['content'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty good :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Let's evaluate our classifiers on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_results = trec_test[['label']].copy()\n",
    "trec_results['Majority'] = maj_class.predict(trec_test['content'])\n",
    "trec_results['Random'] = rnd_class.predict(trec_test['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_results['NaiveBayes'] = nb_class.predict(trec_test['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at basic metrics for each of our predictors. First majority:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.00      0.00      0.00      5027\n",
      "        spam       0.67      1.00      0.80     10057\n",
      "\n",
      "    accuracy                           0.67     15084\n",
      "   macro avg       0.33      0.50      0.40     15084\n",
      "weighted avg       0.44      0.67      0.53     15084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michaelekstrand\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(trec_results['label'], trec_results['Majority']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.33      0.34      0.34      5027\n",
      "        spam       0.67      0.66      0.67     10057\n",
      "\n",
      "    accuracy                           0.56     15084\n",
      "   macro avg       0.50      0.50      0.50     15084\n",
      "weighted avg       0.56      0.56      0.56     15084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(trec_results['label'], trec_results['Random']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      1.00      5027\n",
      "        spam       1.00      1.00      1.00     10057\n",
      "\n",
      "    accuracy                           1.00     15084\n",
      "   macro avg       1.00      1.00      1.00     15084\n",
      "weighted avg       1.00      1.00      1.00     15084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(trec_results['label'], trec_results['NaiveBayes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision for predicting ham is the specificity for predicting spam.  **Think about why that is.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
