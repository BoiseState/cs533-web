1
00:00:04,170 --> 00:00:09,640
But in this video, I'm going to introduce you to the idea of unsupervised learning.

2
00:00:09,640 --> 00:00:13,300
This week we're going to learn about the difference between supervised and unsupervised learning.

3
00:00:13,300 --> 00:00:20,800
You're going to learn how to project data into lower dimensional spaces with matrix factorization and to cluster data points.

4
00:00:20,800 --> 00:00:24,160
So so far, we've been focusing on learning what we're trying to predict a label.

5
00:00:24,160 --> 00:00:30,700
We have a categorical label where we're trying to predict. And this is classification we're trying to classify as spam, not spam fraud.

6
00:00:30,700 --> 00:00:33,370
There's a couple of the examples we've been using.

7
00:00:33,370 --> 00:00:41,020
We can have a continuous label we're trying to predict, in which case we call it, in which case it's three regression.

8
00:00:41,020 --> 00:00:44,620
But this is called we can also try to predict ordinal variables, et cetera.

9
00:00:44,620 --> 00:00:50,890
But this is all called supervised learning. Where we have the key idea here is we have a ground truth for the outcome.

10
00:00:50,890 --> 00:00:56,740
We have observed outcomes for our training data. This is sometimes called a supervisions signal.

11
00:00:56,740 --> 00:01:01,940
And we're trying to learn to predict these known outcomes.

12
00:01:01,940 --> 00:01:07,580
That's that's the heart of what it means to do supervised learning. But.

13
00:01:07,580 --> 00:01:11,000
We can do things without having a supervision signal.

14
00:01:11,000 --> 00:01:18,260
And some of the things we can do without access to a supervision signals, we can try to group instances together what's called clustering,

15
00:01:18,260 --> 00:01:23,180
where we try to find related groups and clustering and multiclass classification are related.

16
00:01:23,180 --> 00:01:26,600
Because if you've got multiple class labels, then you're trying to divide them into that.

17
00:01:26,600 --> 00:01:30,800
Clustering is where you're trying to buy the Met, but you don't have the class labels.

18
00:01:30,800 --> 00:01:34,310
You can try to learn vector spaces for items in order to say,

19
00:01:34,310 --> 00:01:40,880
learn the relationship between items in some cases, also to learn the relationships between features of items.

20
00:01:40,880 --> 00:01:49,190
There's also a middle ground called self supervised learning where you don't have labels in the sense that we use them in supervised learning,

21
00:01:49,190 --> 00:01:54,770
but you extract something that looks like a label from the data and use that as a supervisions signal.

22
00:01:54,770 --> 00:02:01,000
Word and beddings are one example of of self supervised learning.

23
00:02:01,000 --> 00:02:04,540
So why do we want to do this unsupervised learning? There's a few reasons.

24
00:02:04,540 --> 00:02:08,080
One is that it can be useful as a data exploration tool.

25
00:02:08,080 --> 00:02:17,410
If you can find clusters in the data, then that can help guide where you your investigation to understand what's going on in your data.

26
00:02:17,410 --> 00:02:22,930
It can help to reduce data complexity for either visualization or for subsequent learning tasks.

27
00:02:22,930 --> 00:02:25,960
You can use them as inputs into other models and sometimes it's all we have.

28
00:02:25,960 --> 00:02:35,320
We don't have access to labels and we're trying to make sense of our data source. Unsupervised learning techniques can be helpful in order to do that.

29
00:02:35,320 --> 00:02:39,260
So to wrap up unsupervised learning learns patterns from data.

30
00:02:39,260 --> 00:02:51,733
We don't have labels available. It's useful for grouping items together, exploration and as input into other models.

